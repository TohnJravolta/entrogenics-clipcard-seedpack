{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ClipCard Simulation — DevOps / SRE\n\n\n# ClipCard Notebook Plan (auto-generated 2025-10-13)\n\nThis notebook is a scaffold for the **ClipCard (Risk & Recheck)** seedpack.\n\n- **Base schema** (`schema/clipcard.schema.v1.json`) is required.\n- **Extended schema** (`schema/clipcard.schema.v1e.json`) is optional.\n- Works with CSVs under `data/clipmap/*.csv` and any `**/*.clipcard.json` in your repo.\n\n## Inputs\n- `schema/clipcard.schema.v1.json` (required)\n- `schema/clipcard.schema.v1e.json` (optional)\n- `data/clipmap/cards.csv` and `data/clipmap/events.csv` (optional; created by CI)\n- Any `**/*.clipcard.json` examples you add\n\n## Outputs\n- Console metrics and/or CSVs in `notebooks/_out/`\n- Plots (if matplotlib installed)\n- Notes you can copy into Field Reports\n\n> Optional installs (inside a notebook cell):\n>\n> ```\n> %pip install pandas jsonschema matplotlib\n> ```\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\n## What this sim does\n\n- Estimates how often ClipCard triggers on high-risk work\n- Sketches reduction in **false approvals** when ClipCard is used on those items\n- Lets you tweak parameters to match your environment\n\n**This is a toy model**, useful to reason about thresholds before a real field trial.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n# Parameters (edit as needed)\nn_items = 10_000\np_high_impact = 0.25         # share with impact≥4 (1–5 scale)\np_high_uncertainty = 0.30    # share with uncertainty≥4\np_rev_ge4 = 0.10             # reversibility≥4\np_coup_ge4 = 0.12            # coupling≥4\n\nfalse_approval_rate_high = 0.15   # baseline (no ClipCard) on high-risk\nclipcard_effect = 0.60            # multiplicative factor (0.60 = 40% reduction)\n\nimport random\nrandom.seed(42)\n\ndef rand1to5(p_hi):\n    x = random.randint(1,5)\n    if random.random() < p_hi and x < 5:\n        x += 1\n    return x\n\ndef triggers():\n    impact = rand1to5(p_high_impact)\n    uncertainty = rand1to5(p_high_uncertainty)\n    iu = impact * uncertainty >= 18\n    rev = random.random() < p_rev_ge4\n    coup = random.random() < p_coup_ge4\n    ext = rev or coup\n    return iu or ext\n\ntrig_count = 0\nbase_false = 0\nwith_clip_false = 0\n\nfor _ in range(n_items):\n    if triggers():\n        trig_count += 1\n        base_false += (1 if random.random() < false_approval_rate_high else 0)\n        with_clip_false += (1 if random.random() < (false_approval_rate_high * clipcard_effect) else 0)\n\nshare_trig = trig_count / n_items if n_items else 0.0\nbenefit = base_false - with_clip_false\nprint(f\"Items: {n_items}\")\nprint(f\"Triggered: {trig_count} ({share_trig:.1%})\")\nprint(f\"False approvals (base): {base_false}\")\nprint(f\"False approvals (with ClipCard): {with_clip_false}\")\nprint(f\"Benefit (avoided false approvals): {benefit} (~{(benefit/max(base_false,1))*100:.1f}% of base false approvals)\")\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}