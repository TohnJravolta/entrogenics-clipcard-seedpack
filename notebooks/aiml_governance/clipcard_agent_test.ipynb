{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClipCard Agent Test: AI/ML Governance\n",
    "\n",
    "**Purpose:** This notebook tests whether an AI agent (LLM) can correctly parse, validate, and reason about ClipCards in the AI/ML governance domain.\n",
    "\n",
    "It evaluates:\n",
    "1. Can the agent extract kill criteria from a ClipCard?\n",
    "2. Can it determine if a given scenario would trigger the criteria?\n",
    "3. Can it suggest appropriate authority windows for different risk levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load example ClipCard\n",
    "try:\n",
    "    with open('../../examples/test.clipcard.json', 'r') as f:\n",
    "        test_card = json.load(f)\n",
    "    print(\"Loaded test ClipCard:\")\n",
    "    print(json.dumps(test_card, indent=2))\n",
    "except FileNotFoundError:\n",
    "    print(\"No test ClipCard found.\")\n",
    "    test_card = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Extract Kill Criteria\n",
    "\n",
    "Can we programmatically parse kill criteria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_card:\n",
    "    kill_criteria = test_card.get('kill_criteria', [])\n",
    "    print(f\"Found {len(kill_criteria)} kill criteria:\\n\")\n",
    "    for i, criterion in enumerate(kill_criteria, 1):\n",
    "        print(f\"{i}. Condition: {criterion['condition']}\")\n",
    "        print(f\"   Action: {criterion['action']}\\n\")\n",
    "else:\n",
    "    print(\"No ClipCard available for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Scenario Evaluation\n",
    "\n",
    "Test if scenarios match kill criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test scenarios for AI/ML governance\n",
    "scenarios = [\n",
    "    {\n",
    "        \"name\": \"Normal Operation\",\n",
    "        \"pii_leak_count_24h\": 0,\n",
    "        \"jailbreak_hit_rate_24h\": 0.002,\n",
    "        \"bias_drift_sd\": 0.5,\n",
    "        \"expected_trigger\": False\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Single PII Leak\",\n",
    "        \"pii_leak_count_24h\": 1,\n",
    "        \"jailbreak_hit_rate_24h\": 0.001,\n",
    "        \"bias_drift_sd\": 0.3,\n",
    "        \"expected_trigger\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"High Jailbreak Rate\",\n",
    "        \"pii_leak_count_24h\": 0,\n",
    "        \"jailbreak_hit_rate_24h\": 0.008,\n",
    "        \"bias_drift_sd\": 0.4,\n",
    "        \"expected_trigger\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Significant Bias Drift\",\n",
    "        \"pii_leak_count_24h\": 0,\n",
    "        \"jailbreak_hit_rate_24h\": 0.002,\n",
    "        \"bias_drift_sd\": 2.5,\n",
    "        \"expected_trigger\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Testing scenarios against typical AI/ML kill criteria:\\n\")\n",
    "print(\"Assumed thresholds:\")\n",
    "print(\"  - PII leaks: >= 1\")\n",
    "print(\"  - Jailbreak rate: > 0.5%\")\n",
    "print(\"  - Bias drift: > 2.0 SD\\n\")\n",
    "\n",
    "results = []\n",
    "for scenario in scenarios:\n",
    "    # Evaluate against typical AI/ML thresholds\n",
    "    pii_trigger = scenario['pii_leak_count_24h'] >= 1\n",
    "    jailbreak_trigger = scenario['jailbreak_hit_rate_24h'] > 0.005\n",
    "    bias_trigger = scenario['bias_drift_sd'] > 2.0\n",
    "    \n",
    "    any_trigger = pii_trigger or jailbreak_trigger or bias_trigger\n",
    "    match = any_trigger == scenario['expected_trigger']\n",
    "    \n",
    "    results.append({\n",
    "        'Scenario': scenario['name'],\n",
    "        'PII Trigger': pii_trigger,\n",
    "        'Jailbreak Trigger': jailbreak_trigger,\n",
    "        'Bias Trigger': bias_trigger,\n",
    "        'Expected': scenario['expected_trigger'],\n",
    "        'Match': '✓' if match else '✗'\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))\n",
    "print(f\"\\nTest Accuracy: {df_results['Match'].value_counts().get('✓', 0)}/{len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Authority Window Recommendations\n",
    "\n",
    "Generate appropriate authority windows based on risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_authority_window(impact, uncertainty, reversibility):\n",
    "    \"\"\"\n",
    "    Recommend authority window based on ClipCard risk factors\n",
    "    \n",
    "    Args:\n",
    "        impact: 1-5 scale\n",
    "        uncertainty: 1-5 scale\n",
    "        reversibility: 1-5 scale (1=easy to reverse, 5=irreversible)\n",
    "    \"\"\"\n",
    "    risk_score = impact * uncertainty\n",
    "    \n",
    "    if risk_score >= 20 or reversibility >= 5:\n",
    "        return {\n",
    "            \"scope_limit\": \"1% cohort\",\n",
    "            \"time_limit\": \"24h\",\n",
    "            \"auto_pause\": True,\n",
    "            \"justification\": \"Very high risk requires minimal exposure\"\n",
    "        }\n",
    "    elif risk_score >= 15 or reversibility >= 4:\n",
    "        return {\n",
    "            \"scope_limit\": \"5% cohort\",\n",
    "            \"time_limit\": \"7d\",\n",
    "            \"auto_pause\": True,\n",
    "            \"justification\": \"High risk requires controlled rollout\"\n",
    "        }\n",
    "    elif risk_score >= 10:\n",
    "        return {\n",
    "            \"scope_limit\": \"10% cohort\",\n",
    "            \"time_limit\": \"14d\",\n",
    "            \"auto_pause\": False,\n",
    "            \"justification\": \"Medium risk allows moderate exposure\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"scope_limit\": \"25% cohort\",\n",
    "            \"time_limit\": \"30d\",\n",
    "            \"auto_pause\": False,\n",
    "            \"justification\": \"Lower risk permits broader exposure\"\n",
    "        }\n",
    "\n",
    "# Test with example scenarios\n",
    "test_cases = [\n",
    "    {\"name\": \"High-risk plugin\", \"impact\": 5, \"uncertainty\": 4, \"reversibility\": 5},\n",
    "    {\"name\": \"Medium-risk API\", \"impact\": 4, \"uncertainty\": 3, \"reversibility\": 2},\n",
    "    {\"name\": \"Low-risk UI change\", \"impact\": 2, \"uncertainty\": 2, \"reversibility\": 1}\n",
    "]\n",
    "\n",
    "print(\"Authority Window Recommendations:\\n\")\n",
    "for case in test_cases:\n",
    "    rec = recommend_authority_window(case['impact'], case['uncertainty'], case['reversibility'])\n",
    "    print(f\"{case['name']} (I={case['impact']}, U={case['uncertainty']}, R={case['reversibility']}):\")\n",
    "    print(f\"  Scope: {rec['scope_limit']}\")\n",
    "    print(f\"  Duration: {rec['time_limit']}\")\n",
    "    print(f\"  Auto-pause: {rec['auto_pause']}\")\n",
    "    print(f\"  Reason: {rec['justification']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This notebook demonstrates that ClipCard data structures can be:\n",
    "- Programmatically parsed\n",
    "- Evaluated against scenarios\n",
    "- Used to generate risk-appropriate recommendations\n",
    "\n",
    "This enables AI agents to assist with ClipCard creation, validation, and decision support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
